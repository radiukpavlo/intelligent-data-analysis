import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import geopandas as gpd
import joblib
import os

# --- –Ü–º–ø–æ—Ä—Ç–∏ –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –∑ –Ü–Ω—Ç–µ—Ä–Ω–µ—Ç—É ---
import requests
import zipfile

# --- –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –°—Ç–æ—Ä—ñ–Ω–∫–∏ ---
st.set_page_config(
    page_title="–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—è –ö—Ä–∞—ó–Ω –°–≤—ñ—Ç—É",
    page_icon="üåç",
    layout="wide", # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –≤—Å—é —à–∏—Ä–∏–Ω—É
    initial_sidebar_state="expanded"
)

# --- –§—É–Ω–∫—Ü—ñ—ó –¥–ª—è –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –î–∞–Ω–∏—Ö ---
@st.cache_data # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∫–µ—à—É–≤–∞–Ω–Ω—è Streamlit –¥–ª—è –ø—Ä–∏—à–≤–∏–¥—à–µ–Ω–Ω—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
def load_csv_data(data_path, index_col=None):
    if os.path.exists(data_path):
        try:
            return pd.read_csv(data_path, index_col=index_col)
        except Exception as e:
            st.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è CSV —Ñ–∞–π–ª—É '{data_path}': {e}")
            return None
    else:
        st.error(f"–§–∞–π–ª –¥–∞–Ω–∏—Ö –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–∞ —à–ª—è—Ö–æ–º: {data_path}")
        return None

@st.cache_data
def load_joblib_data(data_path):
    if os.path.exists(data_path):
        try:
            return joblib.load(data_path)
        except Exception as e:
            st.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è joblib —Ñ–∞–π–ª—É '{data_path}': {e}")
            return None
    else:
        st.error(f"–§–∞–π–ª joblib –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–∞ —à–ª—è—Ö–æ–º: {data_path}")
        return None

@st.cache_data # –ö–µ—à—É—î–º–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ –≥–µ–æ–¥–∞–Ω—ñ
def load_geodata_manual(data_dir_streamlit="natural_earth_data_streamlit"):
    """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –≥–µ–æ–¥–∞–Ω—ñ –∫—Ä–∞—ó–Ω —Å–≤—ñ—Ç—É –∑ Natural Earth, —Ä–æ–∑–ø–∞–∫–æ–≤—É—î —Ç–∞ –ø–æ–≤–µ—Ä—Ç–∞—î GeoDataFrame."""
    ZIP_URL_ST = "https://naturalearth.s3.amazonaws.com/110m_cultural/ne_110m_admin_0_countries.zip"
    zip_filename_st = os.path.basename(ZIP_URL_ST)
    zip_filepath_st = os.path.join(data_dir_streamlit, zip_filename_st)
    shapefile_name_relative_st = "ne_110m_admin_0_countries.shp"
    shapefile_path_st = os.path.join(data_dir_streamlit, shapefile_name_relative_st)

    if not os.path.exists(shapefile_path_st):
        st.info(f"Shapefile –¥–ª—è –∫–∞—Ä—Ç–∏ ({shapefile_name_relative_st}) –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –°–ø—Ä–æ–±–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è...")
        os.makedirs(data_dir_streamlit, exist_ok=True)

        if not os.path.exists(zip_filepath_st):
            progress_bar = st.progress(0, text="–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≥–µ–æ–¥–∞–Ω–∏—Ö...")
            try:
                response = requests.get(ZIP_URL_ST, stream=True)
                response.raise_for_status()
                total_size = int(response.headers.get('content-length', 0))
                bytes_downloaded = 0
                with open(zip_filepath_st, 'wb') as f:
                    for i, chunk in enumerate(response.iter_content(chunk_size=8192)):
                        f.write(chunk)
                        bytes_downloaded += len(chunk)
                        if total_size > 0:
                            progress_bar.progress(min(100, int(100 * bytes_downloaded / total_size)), text=f"–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≥–µ–æ–¥–∞–Ω–∏—Ö... ({bytes_downloaded // 1024}KB / {total_size // 1024}KB)")
                        else:
                            progress_bar.progress(min(100, i // 10), text=f"–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≥–µ–æ–¥–∞–Ω–∏—Ö... (–±–ª–æ–∫ {i})") # Fallback if no content-length
                progress_bar.progress(100, text="–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≥–µ–æ–¥–∞–Ω–∏—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
                st.success("ZIP-–∞—Ä—Ö—ñ–≤ –≥–µ–æ–¥–∞–Ω–∏—Ö –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ.")
            except requests.exceptions.RequestException as e:
                st.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≥–µ–æ–¥–∞–Ω–∏—Ö: {e}")
                progress_bar.empty()
                return None
            progress_bar.empty()

        st.info(f"–†–æ–∑–ø–∞–∫—É–≤–∞–Ω–Ω—è {zip_filename_st}...")
        try:
            with zipfile.ZipFile(zip_filepath_st, 'r') as zip_ref:
                zip_ref.extractall(data_dir_streamlit)
            st.success("–ì–µ–æ–¥–∞–Ω—ñ —Ä–æ–∑–ø–∞–∫–æ–≤–∞–Ω–æ.")
        except zipfile.BadZipFile:
            st.error(f"–ü–æ–º–∏–ª–∫–∞: –§–∞–π–ª {zip_filename_st} –ø–æ—à–∫–æ–¥–∂–µ–Ω–∏–π. –í–∏–¥–∞–ª—ñ—Ç—å –π–æ–≥–æ —Ç–∞ —Å–ø—Ä–æ–±—É–π—Ç–µ –∑–Ω–æ–≤—É.")
            if os.path.exists(zip_filepath_st): os.remove(zip_filepath_st)
            return None
        except Exception as e:
            st.error(f"–ü–æ–º–∏–ª–∫–∞ —Ä–æ–∑–ø–∞–∫—É–≤–∞–Ω–Ω—è –≥–µ–æ–¥–∞–Ω–∏—Ö: {e}")
            return None
        
        if not os.path.exists(shapefile_path_st):
            st.error(f"Shapefile '{shapefile_name_relative_st}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –ø—ñ—Å–ª—è —Ä–æ–∑–ø–∞–∫—É–≤–∞–Ω–Ω—è.")
            return None
            
    try:
        world_gdf = gpd.read_file(shapefile_path_st)
        st.success("–ì–µ–æ–¥–∞–Ω—ñ –∫—Ä–∞—ó–Ω —Å–≤—ñ—Ç—É —É—Å–ø—ñ—à–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ.")
        return world_gdf
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è shapefile '{shapefile_path_st}': {e}")
        return None

# --- –®–ª—è—Ö–∏ –¥–æ –ó–±–µ—Ä–µ–∂–µ–Ω–∏—Ö –ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ñ–≤ ---
ARTIFACTS_DIR = 'output_artifacts'
DATA_FILE = os.path.join(ARTIFACTS_DIR, 'country_clusters_data.csv')
PROFILES_FILE = os.path.join(ARTIFACTS_DIR, 'cluster_profiles.csv')
CLUSTER_NAMES_FILE = os.path.join(ARTIFACTS_DIR, 'cluster_names.joblib')
PCA_DATA_FILE = os.path.join(ARTIFACTS_DIR, 'pca_data_2c.csv')
MAP_DATA_FILE = os.path.join(ARTIFACTS_DIR, 'world_merged_clusters.csv') # CSV –∑ –¥–∞–Ω–∏–º–∏ –¥–ª—è –∫–∞—Ä—Ç–∏

# --- –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –î–∞–Ω–∏—Ö ---
df_processed_st = load_csv_data(DATA_FILE) # –ú–æ–∂–µ –º–∞—Ç–∏ 'Country Code' –∞–±–æ 'Country Name'
cluster_profiles_st = load_csv_data(PROFILES_FILE, index_col=0)
cluster_names_st = load_joblib_data(CLUSTER_NAMES_FILE)
df_pca_st = load_csv_data(PCA_DATA_FILE) # –ú–∞—î –º—ñ—Å—Ç–∏—Ç–∏ 'Country Name'/'Code', 'PCA1', 'PCA2'
df_map_info_from_csv = load_csv_data(MAP_DATA_FILE) # –î–∞–Ω—ñ –¥–ª—è –∫–∞—Ä—Ç–∏ –∑ CSV, –º—ñ—Å—Ç–∏—Ç—å ISO –∫–æ–¥ —Ç–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏
world_geodata_st = load_geodata_manual() # –ì–µ–æ–º–µ—Ç—Ä—ñ—ó –∫—Ä–∞—ó–Ω

# --- –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è ---
data_load_success = True
if df_processed_st is None: st.error("–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è df_processed_st"); data_load_success = False
if cluster_profiles_st is None: st.error("–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è cluster_profiles_st"); data_load_success = False
if cluster_names_st is None: st.error("–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è cluster_names_st"); data_load_success = False
if df_pca_st is None: st.error("–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è df_pca_st"); data_load_success = False
if df_map_info_from_csv is None: st.error("–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è df_map_info_from_csv"); data_load_success = False
if world_geodata_st is None: st.error("–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è world_geodata_st"); data_load_success = False

if not data_load_success:
    st.warning("–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –≤—Å—ñ –Ω–µ–æ–±—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ. –†–æ–±–æ—Ç–∞ –∑–∞—Å—Ç–æ—Å—É–Ω–∫—É –º–æ–∂–µ –±—É—Ç–∏ –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω–æ—é.")
    st.stop()

# --- –û–±'—î–¥–Ω–∞–Ω–Ω—è –î–∞–Ω–∏—Ö –¥–ª—è –ö–∞—Ä—Ç–∏ ---
world_merged_st = None
if world_geodata_st is not None and df_map_info_from_csv is not None:
    # –í–∏–∑–Ω–∞—á–∞—î–º–æ ISO –∫–æ–ª–æ–Ω–∫—É –≤ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∏—Ö –≥–µ–æ–¥–∞–Ω–∏—Ö (world_geodata_st)
    iso_col_in_geodata = None
    possible_iso_cols_geo = ['ADM0_A3', 'ISO_A3_EH', 'ISO_A3', 'GU_A3']
    for col in possible_iso_cols_geo:
        if col in world_geodata_st.columns:
            iso_col_in_geodata = col
            break
    
    # –í–∏–∑–Ω–∞—á–∞—î–º–æ ISO –∫–æ–ª–æ–Ω–∫—É –≤ df_map_info_from_csv (–∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –∑ CSV)
    # –¶–µ–π CSV –±—É–≤ —Å—Ç–≤–æ—Ä–µ–Ω–∏–π –∑ world_merged –≤ –Ω–æ—É—Ç–±—É—Ü—ñ, —è–∫–∏–π –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞–≤ –ø–µ–≤–Ω—É ISO –∫–æ–ª–æ–Ω–∫—É.
    iso_col_in_csv_data = None
    if iso_col_in_geodata and iso_col_in_geodata in df_map_info_from_csv.columns: # –Ø–∫—â–æ –Ω–∞–∑–≤–∏ —Å–ø—ñ–≤–ø–∞–¥–∞—é—Ç—å
        iso_col_in_csv_data = iso_col_in_geodata
    else: # –Ü–Ω–∞–∫—à–µ, —à—É–∫–∞—î–º–æ —Å–µ—Ä–µ–¥ –º–æ–∂–ª–∏–≤–∏—Ö
        possible_iso_cols_csv = ['iso_a3', 'ADM0_A3', 'ISO_A3_EH', 'ISO_A3'] # 'iso_a3' –∑ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–æ–≥–æ –∫–æ–¥—É
        for col_csv in possible_iso_cols_csv:
            if col_csv in df_map_info_from_csv.columns:
                iso_col_in_csv_data = col_csv
                break
                
    if iso_col_in_geodata and iso_col_in_csv_data:
        st.info(f"–û–±'—î–¥–Ω–∞–Ω–Ω—è –≥–µ–æ–¥–∞–Ω–∏—Ö (–∫–ª—é—á: '{iso_col_in_geodata}') –∑ –¥–∞–Ω–∏–º–∏ –∑ CSV (–∫–ª—é—á: '{iso_col_in_csv_data}').")
        world_merged_st = world_geodata_st.merge(
            df_map_info_from_csv,
            left_on=iso_col_in_geodata,
            right_on=iso_col_in_csv_data,
            how='left',
            suffixes=('_geo', '_csv') # –î–æ–¥–∞—î–º–æ —Å—É—Ñ—ñ–∫—Å–∏, —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –∫–æ–Ω—Ñ–ª—ñ–∫—Ç—ñ–≤ —ñ–º–µ–Ω –∫–æ–ª–æ–Ω–æ–∫
        )
        
        # –û–±—Ä–æ–±–∫–∞ –∫–æ–ª–æ–Ω–æ–∫ –ø—ñ—Å–ª—è –º–µ—Ä–∂—É (–ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç –¥–∞–Ω–∏–º –∑ CSV, —è–∫—â–æ —î —Å—É—Ñ—ñ–∫—Å–∏)
        cols_to_map = {
            'Cluster_Name': 'Cluster_Name_csv', 'KMeans_Cluster': 'KMeans_Cluster_csv',
            '–í–í–ü –Ω–∞ –¥—É—à—É –Ω–∞—Å–µ–ª–µ–Ω–Ω—è': '–í–í–ü –Ω–∞ –¥—É—à—É –Ω–∞—Å–µ–ª–µ–Ω–Ω—è_csv',
            '–¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å –∂–∏—Ç—Ç—è': '–¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å –∂–∏—Ç—Ç—è_csv', '–ù–∞—Å–µ–ª–µ–Ω–Ω—è': '–ù–∞—Å–µ–ª–µ–Ω–Ω—è_csv'
        }
        for target_col, source_col_suffixed in cols_to_map.items():
            if source_col_suffixed in world_merged_st.columns:
                world_merged_st[target_col] = world_merged_st[source_col_suffixed]
            elif target_col not in world_merged_st.columns: # –Ø–∫—â–æ –Ω–µ–º–∞—î –Ω—ñ –∑ _csv, –Ω—ñ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–æ—ó
                 world_merged_st[target_col] = pd.NA


        # –ó–∞–±–µ–∑–ø–µ—á–∏–º–æ, —â–æ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –∫–æ–ª—å–æ—Ä—É —Ç–∞ –ø—ñ–¥–∫–∞–∑–æ–∫ —ñ—Å–Ω—É—é—Ç—å
        world_merged_st['Cluster_Name'] = world_merged_st['Cluster_Name'].fillna('–ù–µ–º–∞—î –¥–∞–Ω–∏—Ö')
        world_merged_st['KMeans_Cluster'] = pd.to_numeric(world_merged_st['KMeans_Cluster'], errors='coerce').fillna(-1).astype(int)
        
        # –ö–æ–ª–æ–Ω–∫–∞ –¥–ª—è –ª–æ–∫–∞—Ü—ñ–π –Ω–∞ –∫–∞—Ä—Ç—ñ - —Ü–µ ISO –∫–æ–¥ –∑ –≥–µ–æ–¥–∞–Ω–∏—Ö
        st.session_state.locations_col_map = iso_col_in_geodata
        # –ö–æ–ª–æ–Ω–∫–∞ –¥–ª—è –Ω–∞–∑–≤ –∫—Ä–∞—ó–Ω
        hover_name_col_map = 'NAME_geo' # –ó–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º –∑ –≥–µ–æ–¥–∞–Ω–∏—Ö
        name_candidates_map = ['NAME_geo', 'ADMIN_geo', 'SOVEREIGNT_geo', 'NAME_csv', 'name_csv'] # –ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç –∑ _geo
        for nc_map in name_candidates_map:
            if nc_map in world_merged_st.columns:
                hover_name_col_map = nc_map
                break
        st.session_state.hover_name_col_map = hover_name_col_map

    else:
        st.error("–ù–µ –≤–¥–∞–ª–æ—Å—è –≤–∏–∑–Ω–∞—á–∏—Ç–∏ –∫–ª—é—á–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏ ISO –¥–ª—è –æ–±'—î–¥–Ω–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö –¥–ª—è –∫–∞—Ä—Ç–∏.")
else:
    if world_geodata_st is None: st.warning("–ì–µ–æ–¥–∞–Ω—ñ –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ.")
    if df_map_info_from_csv is None: st.warning("–î–∞–Ω—ñ –¥–ª—è –∫–∞—Ä—Ç–∏ –∑ CSV –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ.")


# --- –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ó–∞—Å—Ç–æ—Å—É–Ω–∫—É ---
st.title("üåç –Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏–π –ê–Ω–∞–ª—ñ–∑ –ö–ª–∞—Å—Ç–µ—Ä—ñ–≤ –ö—Ä–∞—ó–Ω –°–≤—ñ—Ç—É")
# SELECTED_YEAR –ø–æ—Ç—Ä—ñ–±–Ω–æ –≤–∏–∑–Ω–∞—á–∏—Ç–∏ –∞–±–æ –ø–µ—Ä–µ–¥–∞—Ç–∏
SELECTED_YEAR_ST = 2019 # –í–∏–∑–Ω–∞—á–∏–º–æ —Ç—É—Ç, —è–∫—â–æ –Ω–µ –ø–µ—Ä–µ–¥–∞—î–º–æ –∑–∑–æ–≤–Ω—ñ
st.markdown(f"–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—è –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Å–æ—Ü—ñ–∞–ª—å–Ω–æ-–µ–∫–æ–Ω–æ–º—ñ—á–Ω–∏—Ö —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤ –∑–∞ **{SELECTED_YEAR_ST}** —Ä—ñ–∫.")

# --- –Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è –ö–ª–∞—Å—Ç–µ—Ä—ñ–≤ (–û–ø–∏—Å) ---
cluster_descriptions = {
    0: "**–í–∏—Å–æ–∫–æ—Ä–æ–∑–≤–∏–Ω–µ–Ω—ñ –∫—Ä–∞—ó–Ω–∏:** –ù–∞–π–≤–∏—â–∏–π –í–í–ü, —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å –∂–∏—Ç—Ç—è, –¥–æ—Å—Ç—É–ø –¥–æ —Ç–µ—Ö–Ω–æ–ª–æ–≥—ñ–π —Ç–∞ —ñ–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∏. –í–∏—Å–æ–∫—ñ –≤–∏–∫–∏–¥–∏ CO2, –Ω–∏–∑—å–∫–∞ —á–∞—Å—Ç–∫–∞ —Å/–≥.",
    1: "**–ö—Ä–∞—ó–Ω–∏ —ñ–∑ —Å–µ—Ä–µ–¥–Ω—ñ–º —Ä—ñ–≤–Ω–µ–º —Ä–æ–∑–≤–∏—Ç–∫—É:** –ü–æ–º—ñ—Ä–Ω—ñ –ø–æ–∫–∞–∑–Ω–∏–∫–∏ —Ä–æ–∑–≤–∏—Ç–∫—É –∑–∞ –±—ñ–ª—å—à—ñ—Å—Ç—é —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤. –ù–∞–π–±—ñ–ª—å—à–∞ –≥—Ä—É–ø–∞ –∫—Ä–∞—ó–Ω.",
    2: "**–î–µ–º–æ–≥—Ä–∞—Ñ—ñ—á–Ω—ñ –≥—ñ–≥–∞–Ω—Ç–∏, —â–æ —Ä–æ–∑–≤–∏–≤–∞—é—Ç—å—Å—è:** –î—É–∂–µ –≤–µ–ª–∏–∫–µ –Ω–∞—Å–µ–ª–µ–Ω–Ω—è (–Ü–Ω–¥—ñ—è, –ö–∏—Ç–∞–π). –ü–æ–∫–∞–∑–Ω–∏–∫–∏ —Ä–æ–∑–≤–∏—Ç–∫—É –Ω–∏–∂—á—ñ –∑–∞ —Å–µ—Ä–µ–¥–Ω—ñ, –∞–ª–µ –≤–∏—â—ñ –∑–∞ –Ω–∞–π–º–µ–Ω—à —Ä–æ–∑–≤–∏–Ω–µ–Ω—ñ –∫—Ä–∞—ó–Ω–∏.",
    3: "**–ù–∞–π–º–µ–Ω—à —Ä–æ–∑–≤–∏–Ω–µ–Ω—ñ –∫—Ä–∞—ó–Ω–∏:** –ù–∞–π–Ω–∏–∂—á—ñ –ø–æ–∫–∞–∑–Ω–∏–∫–∏ –í–í–ü, —Ç—Ä–∏–≤–∞–ª–æ—Å—Ç—ñ –∂–∏—Ç—Ç—è, –æ—Å–≤—ñ—Ç–∏, –¥–æ—Å—Ç—É–ø—É –¥–æ —Ç–µ—Ö–Ω–æ–ª–æ–≥—ñ–π —Ç–∞ —ñ–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∏. –ü–µ—Ä–µ–≤–∞–∂–Ω–æ –≤ –ê—Ñ—Ä–∏—Ü—ñ."
}

# --- –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó ---
st.header("üó∫Ô∏è –†–æ–∑–ø–æ–¥—ñ–ª –ö—Ä–∞—ó–Ω –∑–∞ –ö–ª–∞—Å—Ç–µ—Ä–∞–º–∏")
col1, col2 = st.columns(2)

with col1:
    st.subheader("–ö–∞—Ä—Ç–∞ –°–≤—ñ—Ç—É")
    if world_merged_st is not None and 'locations_col_map' in st.session_state:
        try:
            fig_map_st = px.choropleth(world_merged_st,
                                    locations=st.session_state.locations_col_map, # –ö–æ–ª–æ–Ω–∫–∞ ISO –∫–æ–¥—ñ–≤
                                    geojson=world_merged_st.geometry, # –ü–µ—Ä–µ–¥–∞—î–º–æ –≥–µ–æ–º–µ—Ç—Ä—ñ—ó
                                    color="Cluster_Name", # –ö–æ–ª–æ–Ω–∫–∞ –∑ –Ω–∞–∑–≤–∞–º–∏ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤
                                    hover_name=st.session_state.hover_name_col_map, # –ö–æ–ª–æ–Ω–∫–∞ –∑ –Ω–∞–∑–≤–∞–º–∏ –∫—Ä–∞—ó–Ω
                                    hover_data={ 
                                        st.session_state.locations_col_map: False, # –ù–µ –ø–æ–∫–∞–∑—É–≤–∞—Ç–∏ –∫–æ–¥ ISO –¥–≤—ñ—á—ñ
                                        "Cluster_Name": True,
                                        "–í–í–ü –Ω–∞ –¥—É—à—É –Ω–∞—Å–µ–ª–µ–Ω–Ω—è": ":,.0f",
                                        "–¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å –∂–∏—Ç—Ç—è": ":.1f",
                                        "–ù–∞—Å–µ–ª–µ–Ω–Ω—è": ":,.0f"
                                     },
                                    title=f"–ö–ª–∞—Å—Ç–µ—Ä–∏ –†–æ–∑–≤–∏—Ç–∫—É –ö—Ä–∞—ó–Ω ({SELECTED_YEAR_ST})",
                                    color_discrete_map={
                                         "–í–∏—Å–æ–∫–æ—Ä–æ–∑–≤–∏–Ω–µ–Ω—ñ –∫—Ä–∞—ó–Ω–∏": "blue",
                                         "–ö—Ä–∞—ó–Ω–∏ —ñ–∑ —Å–µ—Ä–µ–¥–Ω—ñ–º —Ä—ñ–≤–Ω–µ–º —Ä–æ–∑–≤–∏—Ç–∫—É": "green",
                                         "–î–µ–º–æ–≥—Ä–∞—Ñ—ñ—á–Ω—ñ –≥—ñ–≥–∞–Ω—Ç–∏, —â–æ —Ä–æ–∑–≤–∏–≤–∞—é—Ç—å—Å—è": "orange",
                                         "–ù–∞–π–º–µ–Ω—à —Ä–æ–∑–≤–∏–Ω–µ–Ω—ñ –∫—Ä–∞—ó–Ω–∏": "red",
                                         "–ù–µ–º–∞—î –¥–∞–Ω–∏—Ö": "lightgrey"
                                     },
                                    category_orders={"Cluster_Name": list(cluster_names_st.values()) + ['–ù–µ–º–∞—î –¥–∞–Ω–∏—Ö']}
                                    )
            fig_map_st.update_geos(fitbounds="locations", visible=False)
            fig_map_st.update_layout(margin={"r":0,"t":30,"l":0,"b":0}, height=450, legend_title_text='–ö–ª–∞—Å—Ç–µ—Ä')
            st.plotly_chart(fig_map_st, use_container_width=True)
        except Exception as e:
            st.error(f"–ü–æ–º–∏–ª–∫–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–∞—Ä—Ç–∏: {e}")
            st.dataframe(world_merged_st.drop(columns=['geometry'], errors='ignore').head())
    else:
        st.warning("–ù–µ –≤–¥–∞–ª–æ—Å—è —Å—Ç–≤–æ—Ä–∏—Ç–∏ –∫–∞—Ä—Ç—É —á–µ—Ä–µ–∑ –ø—Ä–æ–±–ª–µ–º–∏ –∑ –¥–∞–Ω–∏–º–∏ –∞–±–æ –≤—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å –∫–ª—é—á–æ–≤–∏—Ö –∫–æ–ª–æ–Ω–æ–∫.")

with col2:
    st.subheader("PCA –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è")
    # –û–±'—î–¥–Ω–∞–Ω–Ω—è df_pca_st –∑ df_processed_st –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è 'Country Name', 'KMeans_Cluster', 'Cluster_Name'
    df_pca_final = None
    if df_pca_st is not None and df_processed_st is not None:
        # df_processed_st –º–æ–∂–µ –º–∞—Ç–∏ —ñ–Ω–¥–µ–∫—Å 'Country Code' –∞–±–æ 'Country Name'
        # df_pca_st –º–∞—î –º—ñ—Å—Ç–∏—Ç–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏–π —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä
        df_processed_for_pca = df_processed_st.reset_index()
        
        merge_key_pca = None
        if 'Country Code' in df_pca_st.columns and 'Country Code' in df_processed_for_pca.columns:
            merge_key_pca = 'Country Code'
        elif 'Country Name' in df_pca_st.columns and 'Country Name' in df_processed_for_pca.columns:
             merge_key_pca = 'Country Name'
        # –Ø–∫—â–æ pca_data_2c.csv –∑–±–µ—Ä—ñ–≥ —ñ–Ω–¥–µ–∫—Å —è–∫ –ø–µ—Ä—à—É –∫–æ–ª–æ–Ω–∫—É –±–µ–∑ –Ω–∞–∑–≤–∏:
        elif df_pca_st.columns[0].startswith('Unnamed: 0') and 'Country Name' in df_processed_for_pca.columns:
             df_pca_st = df_pca_st.rename(columns={df_pca_st.columns[0]: 'Country Name'})
             merge_key_pca = 'Country Name'


        if merge_key_pca:
            cols_to_get = [merge_key_pca, 'KMeans_Cluster', 'Cluster_Name']
            # –î–æ–¥–∞–º–æ 'Country Name', —è–∫—â–æ –∫–ª—é—á 'Country Code', –¥–ª—è hover_name
            if merge_key_pca == 'Country Code' and 'Country Name' in df_processed_for_pca.columns:
                cols_to_get.append('Country Name')
            
            # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ –≤—Å—ñ—Ö –∫–æ–ª–æ–Ω–æ–∫ –≤ df_processed_for_pca
            missing_cols = [c for c in cols_to_get if c not in df_processed_for_pca.columns]
            if not missing_cols:
                df_pca_final = pd.merge(df_pca_st, df_processed_for_pca[cols_to_get], on=merge_key_pca, how='left')
            else:
                st.warning(f"–í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ –≤ df_processed –¥–ª—è –æ–±'—î–¥–Ω–∞–Ω–Ω—è –∑ PCA: {missing_cols}")

        else: # –°–ø—Ä–æ–±–∞ –ø—Ä—è–º–æ–≥–æ –ø—Ä–∏—Å–≤–æ—î–Ω–Ω—è, —è–∫—â–æ –¥–æ–≤–∂–∏–Ω–∏ –∑–±—ñ–≥–∞—é—Ç—å—Å—è (–º–µ–Ω—à –Ω–∞–¥—ñ–π–Ω–æ)
            st.warning("–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ —Å–ø—ñ–ª—å–Ω–∏–π –∫–ª—é—á –¥–ª—è –æ–±'—î–¥–Ω–∞–Ω–Ω—è PCA –¥–∞–Ω–∏—Ö –∑ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—î—é –ø—Ä–æ –∫–ª–∞—Å—Ç–µ—Ä–∏. –°–ø—Ä–æ–±–∞ –ø—Ä—è–º–æ–≥–æ –ø—Ä–∏—Å–≤–æ—î–Ω–Ω—è.")
            if len(df_pca_st) == len(df_processed_for_pca):
                df_pca_st['KMeans_Cluster'] = df_processed_for_pca['KMeans_Cluster'].values
                df_pca_st['Cluster_Name'] = df_processed_for_pca['Cluster_Name'].values
                if 'Country Name' not in df_pca_st.columns and 'Country Name' in df_processed_for_pca.columns:
                     df_pca_st['Country Name'] = df_processed_for_pca['Country Name'].values
                df_pca_final = df_pca_st
            else:
                 st.warning("–†–æ–∑–º—ñ—Ä–∏ PCA –¥–∞–Ω–∏—Ö —Ç–∞ –æ–±—Ä–æ–±–ª–µ–Ω–∏—Ö –¥–∞–Ω–∏—Ö –Ω–µ –∑–±—ñ–≥–∞—é—Ç—å—Å—è –¥–ª—è –ø—Ä—è–º–æ–≥–æ –ø—Ä–∏—Å–≤–æ—î–Ω–Ω—è.")
    
    if df_pca_final is not None and 'PCA1' in df_pca_final.columns and 'PCA2' in df_pca_final.columns and 'KMeans_Cluster' in df_pca_final.columns:
        hover_name_pca = 'Country Name' if 'Country Name' in df_pca_final.columns else (merge_key_pca if merge_key_pca else 'index')

        fig_pca_st = px.scatter(df_pca_final, x='PCA1', y='PCA2',
                             color='KMeans_Cluster', # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —á–∏—Å–ª–æ–≤—É –∫–æ–ª–æ–Ω–∫—É –¥–ª—è –∫–æ–ª—å–æ—Ä—É
                             hover_name=hover_name_pca,
                             hover_data={'KMeans_Cluster': False, 'Cluster_Name': True},
                             title='–ö–ª–∞—Å—Ç–µ—Ä–∏ —É –ü—Ä–æ—Å—Ç–æ—Ä—ñ PCA',
                             labels={'KMeans_Cluster': '–ö–ª–∞—Å—Ç–µ—Ä K-Means'},
                             category_orders={"KMeans_Cluster": sorted(df_pca_final['KMeans_Cluster'].dropna().unique())})
        fig_pca_st.update_layout(xaxis_title='PCA1', yaxis_title='PCA2', height=450, legend_title_text='–ö–ª–∞—Å—Ç–µ—Ä')
        fig_pca_st.update_traces(marker=dict(size=8, opacity=0.8))
        st.plotly_chart(fig_pca_st, use_container_width=True)
    else:
        st.warning("–ù–µ–æ–±—Ö—ñ–¥–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ ('PCA1', 'PCA2', 'KMeans_Cluster', 'Country Name'/'Code') –≤—ñ–¥—Å—É—Ç–Ω—ñ –¥–ª—è PCA –≥—Ä–∞—Ñ—ñ–∫–∞.")
        if df_pca_final is not None: st.dataframe(df_pca_final.head())
        elif df_pca_st is not None: st.dataframe(df_pca_st.head())


st.divider()

# --- –î–µ—Ç–∞–ª—å–Ω–∏–π –ê–Ω–∞–ª—ñ–∑ –ö–ª–∞—Å—Ç–µ—Ä—ñ–≤ ---
st.header("üìä –î–µ—Ç–∞–ª—å–Ω–∏–π –ü—Ä–æ—Ñ—ñ–ª—å –ö–ª–∞—Å—Ç–µ—Ä—ñ–≤")

if cluster_names_st and cluster_profiles_st is not None:
    cluster_options = {i: f"–ö–ª–∞—Å—Ç–µ—Ä {i}: {name}" for i, name in cluster_names_st.items() if i in cluster_profiles_st.index}
    if not cluster_options:
        st.warning("–ù–µ–º–∞—î –¥–æ—Å—Ç—É–ø–Ω–∏—Ö –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤ –¥–ª—è –≤–∏–±–æ—Ä—É.")
    else:
        selected_cluster_label = st.selectbox(
            "–û–±–µ—Ä—ñ—Ç—å –∫–ª–∞—Å—Ç–µ—Ä –¥–ª—è –ø–µ—Ä–µ–≥–ª—è–¥—É:",
            options=list(cluster_options.keys()),
            format_func=lambda x: cluster_options[x]
        )

        selected_cluster_name = cluster_names_st[selected_cluster_label]
        selected_cluster_desc = cluster_descriptions.get(selected_cluster_label, "–û–ø–∏—Å –¥–ª—è —Ü—å–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞ –≤—ñ–¥—Å—É—Ç–Ω—ñ–π.")

        st.subheader(f"–ü—Ä–æ—Ñ—ñ–ª—å: {selected_cluster_name} (–ö–ª–∞—Å—Ç–µ—Ä {selected_cluster_label})")
        st.markdown(selected_cluster_desc)

        profile_data = cluster_profiles_st.loc[selected_cluster_label]
        
        col_prof1, col_prof2 = st.columns([0.6, 0.4])

        with col_prof1:
            st.markdown("**–†–∞–¥–∞—Ä–Ω–∞ –¥—ñ–∞–≥—Ä–∞–º–∞ –ø—Ä–æ—Ñ—ñ–ª—é (–Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è):**")
            from sklearn.preprocessing import MinMaxScaler # –õ–æ–∫–∞–ª—å–Ω–∏–π —ñ–º–ø–æ—Ä—Ç
            scaler_profiles = MinMaxScaler()
            # –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ —Ç—ñ–ª—å–∫–∏ —á–∏—Å–ª–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏, —è–∫—â–æ —î –Ω–µ—á–∏—Å–ª–æ–≤—ñ
            numeric_profile_cols = cluster_profiles_st.select_dtypes(include=np.number).columns
            if not numeric_profile_cols.empty:
                profiles_scaled_np = scaler_profiles.fit_transform(cluster_profiles_st[numeric_profile_cols])
                df_profiles_scaled = pd.DataFrame(profiles_scaled_np, index=cluster_profiles_st.index, columns=numeric_profile_cols)

                fig_radar_single = go.Figure()
                categories = df_profiles_scaled.columns
                fig_radar_single.add_trace(go.Scatterpolar(
                    r=df_profiles_scaled.loc[selected_cluster_label].values,
                    theta=categories,
                    fill='toself',
                    name=selected_cluster_name
                ))
                fig_radar_single.update_layout(
                    polar=dict(radialaxis=dict(visible=True, range=[0, 1])),
                    showlegend=False,
                    title=f"–ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π –ø—Ä–æ—Ñ—ñ–ª—å: {selected_cluster_name}",
                    height=400
                )
                st.plotly_chart(fig_radar_single, use_container_width=True)
            else:
                st.warning("–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ —á–∏—Å–ª–æ–≤–∏—Ö –∫–æ–ª–æ–Ω–æ–∫ —É –ø—Ä–æ—Ñ—ñ–ª—è—Ö –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤ –¥–ª—è —Ä–∞–¥–∞—Ä–Ω–æ—ó –¥—ñ–∞–≥—Ä–∞–º–∏.")

            st.markdown("**–¢–æ—á–Ω—ñ —Å–µ—Ä–µ–¥–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è:**")
            st.dataframe(profile_data.to_frame(name='–°–µ—Ä–µ–¥–Ω—î –ó–Ω–∞—á–µ–Ω–Ω—è').style.format("{:,.2f}"))

        with col_prof2:
            st.markdown(f"**–ö—Ä–∞—ó–Ω–∏, —â–æ –≤—Ö–æ–¥—è—Ç—å –¥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞ {selected_cluster_label}:**")
            if df_processed_st is not None and 'KMeans_Cluster' in df_processed_st.columns:
                # –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–∫–∏ –∑ –Ω–∞–∑–≤–æ—é –∫—Ä–∞—ó–Ω–∏ (–º–æ–∂–µ –±—É—Ç–∏ —ñ–Ω–¥–µ–∫—Å–æ–º –∞–±–æ –∫–æ–ª–æ–Ω–∫–æ—é)
                country_name_col_for_list = 'Country Name' # –ó–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º
                if 'Country Name' not in df_processed_st.columns:
                    if df_processed_st.index.name == 'Country Name':
                        countries_in_cluster = df_processed_st[df_processed_st['KMeans_Cluster'] == selected_cluster_label].index.tolist()
                    elif 'Country Code' in df_processed_st.columns: # –Ø–∫—â–æ —î Country Code, –∞ Country Name - –Ω—ñ
                         countries_in_cluster = df_processed_st[df_processed_st['KMeans_Cluster'] == selected_cluster_label]['Country Code'].tolist()
                         country_name_col_for_list = 'Country Code' # –ü–æ–∫–∞–∑—É—î–º–æ –∫–æ–¥–∏, —è–∫—â–æ –Ω–µ–º–∞—î –Ω–∞–∑–≤
                    else: # –ù–µ–º–∞—î –Ω—ñ 'Country Name', –Ω—ñ 'Country Code' —è–∫ –∫–æ–ª–æ–Ω–∫–∏ –∞–±–æ —ñ–Ω–¥–µ–∫—Å—É
                         countries_in_cluster = []
                         st.warning("–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ –∫–æ–ª–æ–Ω–∫—É –∑ –Ω–∞–∑–≤–∞–º–∏/–∫–æ–¥–∞–º–∏ –∫—Ä–∞—ó–Ω —É `df_processed_st`.")
                else: # 'Country Name' —î –∫–æ–ª–æ–Ω–∫–æ—é
                    countries_in_cluster = df_processed_st[df_processed_st['KMeans_Cluster'] == selected_cluster_label][country_name_col_for_list].tolist()
                
                if countries_in_cluster:
                    st.dataframe(pd.DataFrame({f"–ù–∞–∑–≤–∏ –∫—Ä–∞—ó–Ω (–∞–±–æ –∫–æ–¥–∏) —É –∫–ª–∞—Å—Ç–µ—Ä—ñ {selected_cluster_label}": countries_in_cluster}), height=450, use_container_width=True)
                    st.caption(f"–í—Å—å–æ–≥–æ –∫—Ä–∞—ó–Ω —É –∫–ª–∞—Å—Ç–µ—Ä—ñ: {len(countries_in_cluster)}")
                else:
                    st.info("–ù–µ–º–∞—î –∫—Ä–∞—ó–Ω –¥–ª—è –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è —É —Ü—å–æ–º—É –∫–ª–∞—Å—Ç–µ—Ä—ñ (–∞–±–æ –Ω–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ —ó—Ö –Ω–∞–∑–≤–∏).")
            else:
                st.warning("–î–∞–Ω—ñ `df_processed_st` –∞–±–æ –∫–æ–ª–æ–Ω–∫–∞ 'KMeans_Cluster' –Ω–µ –¥–æ—Å—Ç—É–ø–Ω—ñ.")
else:
    st.error("–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –Ω–∞–∑–≤–∏ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤ –∞–±–æ —ó—Ö –ø—Ä–æ—Ñ—ñ–ª—ñ. –î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –Ω–µ–º–æ–∂–ª–∏–≤–∏–π.")


# --- –ó–∞–≤–µ—Ä—à–µ–Ω–Ω—è ---
st.sidebar.info(
    f"""
    **–ü—Ä–æ –ø—Ä–æ—î–∫—Ç:**
    –¶–µ–π –∑–∞—Å—Ç–æ—Å—É–Ω–æ–∫ –≤—ñ–∑—É–∞–ª—ñ–∑—É—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—ó –∫—Ä–∞—ó–Ω —Å–≤—ñ—Ç—É
    –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Å–æ—Ü—ñ–∞–ª—å–Ω–æ-–µ–∫–æ–Ω–æ–º—ñ—á–Ω–∏—Ö —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤ WDI –∑–∞ {SELECTED_YEAR_ST} —Ä—ñ–∫.
    –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–æ –∞–ª–≥–æ—Ä–∏—Ç–º K-Means (k=4).

    **–ù–∞–≤—ñ–≥–∞—Ü—ñ—è:**
    - –ü–µ—Ä–µ–≥–ª—è–¥–∞–π—Ç–µ –∫–∞—Ä—Ç—É —Ç–∞ PCA –≥—Ä–∞—Ñ—ñ–∫.
    - –í–∏–±–µ—Ä—ñ—Ç—å –∫–ª–∞—Å—Ç–µ—Ä —É –≤–∏–ø–∞–¥–∞—é—á–æ–º—É —Å–ø–∏—Å–∫—É –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É –ø—Ä–æ—Ñ—ñ–ª—é —Ç–∞ —Å–ø–∏—Å–∫—É –∫—Ä–∞—ó–Ω.
    """
)
# ==============================================================================
# –ö—ñ–Ω–µ—Ü—å –∫–æ–¥—É –¥–ª—è —Ñ–∞–π–ª—É app.py
# ==============================================================================